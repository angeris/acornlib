from nat.lattice import Nat
from list.list_base import List, map
from add_comm_monoid import AddCommMonoid
from add_semigroup import add_fn
from semiring import Semiring
from semigroup import mul_fn
from util import compose

numerals Nat

/// Computes the sum of all elements in a list (requires elements to form an additive commutative monoid).
define sum[A: AddCommMonoid](items: List[A]) -> A {
    match items {
        List.nil {
            A.0
        }
        List.cons(head, tail) {
            head + sum(tail)
        }
    }
}

/// Computes the partial sum of a series up to index n.
/// Returns the sum of f(0) + f(1) + ... + f(n-1).
define partial[A: AddCommMonoid](f: Nat -> A, n: Nat) -> A {
    sum(map(n.range, f))
}

/// The partial sum of a single element equals that element.
theorem partial_one[A: AddCommMonoid](f: Nat -> A) {
    partial(f, 1) = f(0)
} by {
    map(List.singleton(0), f) = List.singleton(f(0))
}

/// Summing two mapped lists equals mapping with the pointwise sum of functions.
theorem map_sum_add[T, A: AddCommMonoid](list: List[T], f: T -> A, g: T -> A) {
    sum(map(list, f)) + sum(map(list, g)) = sum(map(list, add_fn(f, g)))
} by {
    define p(l: List[T]) -> Bool {
        sum(map(l, f)) + sum(map(l, g)) = sum(map(l, add_fn(f, g)))
    }

    // Base case: empty list
    p(List.nil)

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            // Induction hypothesis: sum(map(tail, f)) + sum(map(tail, g)) = sum(map(tail, add_fn(f, g)))

            // LHS: sum(map(List.cons(head, tail), f)) + sum(map(List.cons(head, tail), g))

            // RHS: sum(map(List.cons(head, tail), add_fn(f, g)))

            // Now we need to show:
            // (f(head) + sum(map(tail, f))) + (g(head) + sum(map(tail, g))) = (f(head) + g(head)) + sum(map(tail, add_fn(f, g)))

            // Using the induction hypothesis:

            // Using associativity and commutativity:
            f(head) + (g(head) + (sum(map(tail, f)) + sum(map(tail, g)))) = (f(head) + g(head)) + (sum(map(tail, f)) + sum(map(tail, g)))
            (f(head) + g(head)) + (sum(map(tail, f)) + sum(map(tail, g))) = (f(head) + g(head)) + sum(map(tail, add_fn(f, g)))

            p(List.cons(head, tail))
        }
    }
}

/// Adding two partial sums equals the partial sum of pointwise sums.
theorem partial_add[A: AddCommMonoid](f: Nat -> A, g: Nat -> A, n: Nat) {
    partial(f, n) + partial(g, n) = partial(add_fn(f, g), n)
} by {
    // Expand the definitions of partial

    // Use map_sum_add theorem
}

/// Helper function for scalar multiplication.
define scalar_mul[S: Semiring](c: S, x: S) -> S {
    c * x
}

/// Multiplying a constant by a sum equals the sum of the products.
theorem sum_scalar_mul[S: Semiring](c: S, list: List[S]) {
    c * sum(list) = sum(map(list, scalar_mul(c)))
} by {
    define p(xs: List[S]) -> Bool {
        c * sum(xs) = sum(map(xs, scalar_mul(c)))
    }

    // Base case: c * sum(nil) = sum(map(nil, scalar_mul(c)))
    p(List.nil)

    // Inductive step
    forall(head: S, tail: List[S]) {
        if p(tail) {
            // Induction hypothesis: c * sum(tail) = sum(map(tail, scalar_mul(c)))

            // Left side: c * sum(cons(head, tail))

            // Apply induction hypothesis

            // Right side: sum(map(cons(head, tail), scalar_mul(c)))

            c * sum(List.cons(head, tail)) = sum(map(List.cons(head, tail), scalar_mul(c)))
        }
    }
}

theorem sum_add[A: AddCommMonoid](left: List[A], right: List[A]) {
    sum(left + right) = sum(left) + sum(right)
} by {
    define p(x: List[A]) -> Bool {
        sum(x + right) = sum(x) + sum(right)
    }

    // Base case: sum(nil + right) = sum(nil) + sum(right)
    p(List.nil)

    // Inductive step
    forall(head: A, tail: List[A]) {
        if p(tail) {
            // Induction hypothesis: sum(tail + right) = sum(tail) + sum(right)

            // Left side: sum(List.cons(head, tail) + right)

            // Use induction hypothesis

            // Right side: sum(List.cons(head, tail)) + sum(right)

            // Use associativity

            // Therefore
            p(List.cons(head, tail))
        }
    }
}

theorem map_add[T, U](left: List[T], right: List[T], f: T -> U) {
    map(left + right, f) = map(left, f) + map(right, f)
} by {
    define p(x: List[T]) -> Bool {
        map(x + right, f) = map(x, f) + map(right, f)
    }

    // Base case: map(nil + right, f) = map(nil, f) + map(right, f)
    p(List.nil)

    // Inductive step

    forall(head: T, tail: List[T]) {
        if p(tail) {
            // Induction hypothesis: map(tail + right, f) = map(tail, f) + map(right, f)

            // Left side: map(List.cons(head, tail) + right, f)

            // Use induction hypothesis

            // Right side: map(List.cons(head, tail), f) + map(right, f)

            // Therefore
            p(List.cons(head, tail))
        }
    }
}

theorem map_append[T, U](initial: List[T], last: T, f: T -> U) {
    map(initial.append(last), f) = map(initial, f).append(f(last))
}

theorem sum_append[A: AddCommMonoid](initial: List[A], last: A) {
    sum(initial.append(last)) = sum(initial) + last
}

theorem add_assoc[T](a: List[T], b: List[T], c: List[T]) {
    (a + b) + c = a + (b + c)
} by {
    define p(x: List[T]) -> Bool {
        (x + b) + c = x + (b + c)
    }

    // Base case: (nil + b) + c = nil + (b + c)
    p(List.nil)

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            // Induction hypothesis: (tail + b) + c = tail + (b + c)

            // Left side: (List.cons(head, tail) + b) + c

            // Use induction hypothesis

            // Right side: List.cons(head, tail) + (b + c)

            // Therefore
            p(List.cons(head, tail))
        }
    }
}

theorem map_singleton[T, U](f: T -> U, x: T) {
    map(List.singleton(x), f) = List.singleton(f(x))
}

theorem length_zero_imp_nil[T](list: List[T]) {
    list.length = Nat.0 implies list = List.nil[T]
}

theorem add_to_nil[T](a: List[T], b: List[T]) {
    a + b = List.nil[T] implies a = List.nil[T] and b = List.nil[T]
}

theorem append_not_nil[T](a: List[T], t: T) {
    a.append(t) != List.nil[T]
}

theorem map_map[T, U, V](items: List[T], f: T -> U, g: U -> V) {
    map(map(items, f), g) = map(items, compose(g, f))
} by {
    define p(x: List[T]) -> Bool {
        map(map(x, f), g) = map(x, compose(g, f))
    }

    // Base case
    p(List.nil)

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            // Left side

            // Use induction hypothesis

            // Right side

            // Therefore
            p(List.cons(head, tail))
        }
    }
}

/// Distributing scalar multiplication through a partial sum.
theorem partial_scalar_mul[S: Semiring](c: S, f: Nat -> S, n: Nat) {
    c * partial(f, n) = partial(mul_fn(c, f), n)
} by {
    // Expand the definition of partial

    // Use sum_scalar_mul theorem

    // Use the map_map theorem

    // Show that compose(scalar_mul(c), f) = mul_fn(c, f)

    // The two functions are equal
    compose(scalar_mul(c), f) = mul_fn(c, f)

}

/// Shifting indices in a partial sum by adding 1.
theorem partial_shift_suc[A: AddCommMonoid](f: Nat -> A, n: Nat) {
    f(0) + partial(compose(f, Nat.suc), n) = partial(f, n.suc)
} by {
    define p(k: Nat) -> Bool {
        f(0) + partial(compose(f, Nat.suc), k) = partial(f, k.suc)
    }

    // Base case: k = 0

    f(0) + partial(compose(f, Nat.suc), 0) = partial(f, 0.suc)

    // Inductive step
    forall(k: Nat) {
        if p(k) {
            // Induction hypothesis: f(0) + partial(compose(f, Nat.suc), k) = partial(f, k.suc)

            // Expand partial(compose(f, Nat.suc), k.suc)
            sum(map(k.suc.range, compose(f, Nat.suc))) = partial(compose(f, Nat.suc), k) + f(k.suc)

            // Left side

            // Apply induction hypothesis
            (f(0) + partial(compose(f, Nat.suc), k)) + f(k.suc) = partial(f, k.suc) + f(k.suc)

            // Right side: expand partial(f, k.suc.suc)
            sum(map(k.suc.suc.range, f)) = partial(f, k.suc) + f(k.suc)

            p(k.suc)
        }
    }

}

/// Splitting off the last term of a partial sum.
theorem partial_split_last[A: AddCommMonoid](f: Nat -> A, n: Nat) {
    partial(f, n.suc) = partial(f, n) + f(n)
} by {
    // Expand partial(f, n.suc)
}

/// Function extensionality for partial sums: if two functions agree on all relevant indices, their partial sums are equal.
theorem partial_pointwise_eq[A: AddCommMonoid](f: Nat -> A, g: Nat -> A, n: Nat) {
    (forall(k: Nat) { k < n implies f(k) = g(k) }) implies partial(f, n) = partial(g, n)
} by {
    define p(m: Nat) -> Bool {
        (forall(k: Nat) { k < m implies f(k) = g(k) }) implies partial(f, m) = partial(g, m)
    }

    // Base case: m = 0
    p(0)

    // Inductive step
    forall(m: Nat) {
        if p(m) {
            if forall(k: Nat) { k < m.suc implies f(k) = g(k) } {
                // Split into k < m and k = m
                // Apply induction hypothesis
                // Handle k = m
                // Use partial_split_last
                partial(f, m.suc) = partial(g, m) + f(m)
                partial(f, m.suc) = partial(g, m.suc)
            }
        }
    }

    p(n)
}

/// Helper: reverses the indices of a function over a range.
/// reverse_index(g, n, i) = g(n - i)
define reverse_index[A](g: Nat -> A, n: Nat, i: Nat) -> A {
    g(n - i)
}

/// Summing a function in reverse order equals summing in forward order.
theorem partial_reverse[A: AddCommMonoid](g: Nat -> A, n: Nat) {
    partial(g, n.suc) = partial(reverse_index(g, n), n.suc)
} by {
    // Prove by induction on n
    define p(m: Nat) -> Bool {
        partial(g, m.suc) = partial(reverse_index(g, m), m.suc)
    }

    // Base case: m = 0
    // partial(g, 1) = g(0)
    // partial(reverse_index(g, 0), 1) = reverse_index(g, 0, 0) = g(0 - 0) = g(0)
    partial(g, Nat.1) = g(Nat.0)
    reverse_index(g, Nat.0, Nat.0) = g(Nat.0 - Nat.0)
    Nat.0 - Nat.0 = Nat.0
    reverse_index(g, Nat.0, Nat.0) = g(Nat.0)
    partial(reverse_index(g, Nat.0), Nat.1) = reverse_index(g, Nat.0, Nat.0)
    partial(g, Nat.1) = partial(reverse_index(g, Nat.0), Nat.1)
    p(Nat.0)

    // Inductive step
    forall(m: Nat) {
        if p(m) {
            // Goal: partial(g, m.suc.suc) = partial(reverse_index(g, m.suc), m.suc.suc)
            // IH: partial(g, m.suc) = partial(reverse_index(g, m), m.suc)

            // Expand both sides using partial_split_last
            partial(g, m.suc.suc) = partial(g, m.suc) + g(m.suc)
            partial(reverse_index(g, m.suc), m.suc.suc) = partial(reverse_index(g, m.suc), m.suc) + reverse_index(g, m.suc, m.suc)

            // Evaluate reverse_index(g, m.suc, m.suc)
            reverse_index(g, m.suc, m.suc) = g(m.suc - m.suc)
            m.suc - m.suc = Nat.0
            reverse_index(g, m.suc, m.suc) = g(Nat.0)

            // So the goal becomes:
            // partial(g, m.suc) + g(m.suc) = partial(reverse_index(g, m.suc), m.suc) + g(0)

            // By IH: partial(g, m.suc) = partial(reverse_index(g, m), m.suc)
            // So: partial(reverse_index(g, m), m.suc) + g(m.suc) = partial(reverse_index(g, m.suc), m.suc) + g(0)

            // Now expand:
            // partial(reverse_index(g, m), m.suc) = g(m) + g(m-1) + ... + g(0)
            // partial(reverse_index(g, m.suc), m.suc) = g(m.suc) + g(m) + ... + g(1)
            //
            // So:
            // LHS = [g(m) + ... + g(0)] + g(m.suc) = g(m.suc) + g(m) + ... + g(0)
            // RHS = [g(m.suc) + g(m) + ... + g(1)] + g(0) = g(m.suc) + g(m) + ... + g(0)
            //
            // These are equal by commutativity of addition.

            // Use partial_drop_first to relate reverse_index(g, m.suc) to reverse_index(g, m)
            m.suc > Nat.0
            partial(reverse_index(g, m.suc), m.suc) = reverse_index(g, m.suc, Nat.0) + partial(compose(reverse_index(g, m.suc), Nat.suc), m.suc - Nat.1)
            reverse_index(g, m.suc, Nat.0) = g(m.suc - Nat.0)
            m.suc - Nat.0 = m.suc
            reverse_index(g, m.suc, Nat.0) = g(m.suc)
            m.suc - Nat.1 = m
            partial(reverse_index(g, m.suc), m.suc) = g(m.suc) + partial(compose(reverse_index(g, m.suc), Nat.suc), m)

            // Show that compose(reverse_index(g, m.suc), Nat.suc)(i) = reverse_index(g, m, i) for all i < m
            forall(i: Nat) {
                if i < m {
                    compose(reverse_index(g, m.suc), Nat.suc, i) = reverse_index(g, m.suc, i.suc)
                    reverse_index(g, m.suc, i.suc) = g(m.suc - i.suc)
                    m.suc - i.suc = m - i
                    reverse_index(g, m, i) = g(m - i)
                    compose(reverse_index(g, m.suc), Nat.suc, i) = reverse_index(g, m, i)
                }
            }

            // Since the functions agree on all indices < m, use partial_pointwise_eq
            partial_pointwise_eq(compose(reverse_index(g, m.suc), Nat.suc), reverse_index(g, m), m)
            partial(compose(reverse_index(g, m.suc), Nat.suc), m) = partial(reverse_index(g, m), m)

            // So partial(reverse_index(g, m.suc), m.suc) = g(m.suc) + partial(reverse_index(g, m), m)
            partial(reverse_index(g, m.suc), m.suc) = g(m.suc) + partial(reverse_index(g, m), m)

            // Use partial_split_last on partial(reverse_index(g, m), m.suc)
            partial(reverse_index(g, m), m.suc) = partial(reverse_index(g, m), m) + reverse_index(g, m, m)
            reverse_index(g, m, m) = g(m - m)
            m - m = Nat.0
            reverse_index(g, m, m) = g(Nat.0)
            partial(reverse_index(g, m), m.suc) = partial(reverse_index(g, m), m) + g(Nat.0)

            // Now we can show:
            // partial(reverse_index(g, m), m.suc) + g(m.suc)
            // = [partial(reverse_index(g, m), m) + g(0)] + g(m.suc)
            // = partial(reverse_index(g, m), m) + g(0) + g(m.suc)
            // = partial(reverse_index(g, m), m) + g(m.suc) + g(0)   [commutativity]
            // = [g(m.suc) + partial(reverse_index(g, m), m)] + g(0)
            // = partial(reverse_index(g, m.suc), m.suc) + g(0)

            partial(reverse_index(g, m), m.suc) + g(m.suc) = partial(reverse_index(g, m.suc), m.suc) + g(Nat.0)

            p(m.suc)
        }
    }
}

/// Extract the first term from a partial sum.
theorem partial_drop_first[A: AddCommMonoid](f: Nat -> A, n: Nat) {
    n > 0 implies partial(f, n) = f(0) + partial(compose(f, Nat.suc), n - 1)
}

/// Split a partial sum into first term, middle terms, and last term.
theorem partial_split_first_last[A: AddCommMonoid](f: Nat -> A, n: Nat) {
    n >= 2 implies partial(f, n) = f(0) + partial(compose(f, Nat.suc), n - 2) + f(n - 1)
} by {
    if n >= 2 {
        // Use partial_drop_first to extract f(0)

        // Now apply partial_split_last to partial(compose(f, Nat.suc), n - 1)
        // Need to show n - 1 >= 1 when n >= 2
        let (n_minus_1: Nat) satisfy { n_minus_1.suc = n }

        // Since n >= 2, we have n_minus_1 >= 1

        let (n_minus_2: Nat) satisfy { n_minus_2.suc = n_minus_1 }
        n - 2 = n_minus_2

        partial(f, n) = f(0) + partial(compose(f, Nat.suc), n - 2) + f(n - 1)
    }
}

theorem map_length[T, U](list: List[T], f: T -> U) {
    map(list, f).length = list.length
} by {
    define p(x: List[T]) -> Bool {
        map(x, f).length = x.length
    }

    // Base case
    p(List.nil[T])

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            map(List.cons(head, tail), f).length = List.cons(head, tail).length
        }
    }

    p(list)
}

theorem map_contains[T, U](list: List[T], f: T -> U, item: U) {
    map(list, f).contains(item) implies exists(x: T) {
        list.contains(x) and f(x) = item
    }
} by {
    define p(x: List[T]) -> Bool {
        map(x, f).contains(item) implies exists(y: T) {
            x.contains(y) and f(y) = item
        }
    }

    // Base case
    p(List.nil[T])

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            if map(List.cons(head, tail), f).contains(item) {
                // If the map contains the item, it must be from either head or tail
                if map(tail, f).contains(item) {
                    // If tail contains the item, then we can use the induction hypothesis
                } else {
                    // If head is the source of the item
                    p(List.cons(head, tail))
                }
            }
            p(List.cons(head, tail))
        }
    }

    List.induction(function (l: List[T]) {
        p(l)
    })
}

theorem map_preimage_contains[T, U](list: List[T], f: T -> U, item: T) {
    list.contains(item) implies map(list, f).contains(f(item))
} by {
    define p(x: List[T]) -> Bool {
        x.contains(item) implies map(x, f).contains(f(item))
    }

    // Base case
    p(List.nil[T])

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            if List.cons(head, tail).contains(item) {
                if head = item {
                    map(List.cons(head, tail), f).contains(f(item))
                } else {
                    p(List.cons(head, tail))
                }
            }
            p(List.cons(head, tail))
        }
    }

    List.induction(function (l: List[T]) {
        p(l)
    })
}

theorem pigeonhole_unique_map[T, U](items: List[T], f: T -> U) {
    items.is_unique and not map(items, f).is_unique implies
    exists(x: T, y: T) {
        x != y and f(x) = f(y)
    }
} by {
    define p(l: List[T]) -> Bool {
        l.is_unique and not map(l, f).is_unique implies
        exists(a: T, b: T) {
            a != b and f(a) = f(b)
        }
    }

    define has_duplicate(list: List[U]) -> Bool {
        exists(y: U) {
            list.count(y) > 1
        }
    }

    // Base case: empty list
    p(List.nil[T])

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            if List.cons(head, tail).is_unique and not map(List.cons(head, tail), f).is_unique {
                let tail_map = map(tail, f)
                // Either tail already has duplicate or not
                if has_duplicate(tail_map) {
                    not map(tail, f).is_unique

                } else {
                    // If tail_map does not have a duplicate, f(head) is the
                    // duplicate
                    let dup = f(head)

                    tail_map.contains(dup)
                    let x: T satisfy {
                        tail.contains(x) and f(x) = dup
                    }

                    p(List.cons(head, tail))
                }

                p(List.cons(head, tail))
            }
            p(List.cons(head, tail))
        }
    }
}

theorem pigeonhole_map[U, T](items: List[T], f: T -> U) {
    items.is_unique and items.length > map(items, f).unique.length implies
    exists(x: T, y: T) {
        x != y and f(x) = f(y)
    }
} by {
    not map(items, f).is_unique
}

attributes List[T] {
    /// Yields the list without its first element.
    /// Yields nil for an empty list.
    define tail(self) -> List[T] {
        match self {
            List.nil {
                List.nil[T]
            }
            List.cons(h, t) {
                t
            }
        }
    }

    /// Removes the first n elements from the list.
    define drop(self, n: Nat) -> List[T] {
        match n {
            Nat.0 {
                self
            }
            Nat.suc(pred) {
                self.tail.drop(pred)
            }
        }
    }
}

theorem tail_cancels_cons[T](a: T, b: List[T]) {
    List.cons(a, b).tail = b
}

theorem drop_zero[T](a: List[T]) {
    a.drop(Nat.0) = a
}

theorem drop_one[T](a: List[T]) {
    a.drop(Nat.1) = a.tail
}

theorem drop_cancels_add[T](a: List[T], b: List[T]) {
    (a + b).drop(a.length) = b
} by {
    define p(x: List[T]) -> Bool {
        (x + b).drop(x.length) = b
    }

    // Base case
    p(List.nil)

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            // Induction hypothesis: (tail + b).drop(tail.length) = b

            // Left side

            // Use induction hypothesis

            // Therefore
            p(List.cons(head, tail))
        }
    }
}

theorem drop_twice[T](a: List[T], m: Nat, n: Nat) {
    a.drop(m).drop(n) = a.drop(m + n)
} by {
    define f(x: Nat) -> Bool {
        forall(l: List[T], k: Nat) {
            l.drop(x).drop(k) = l.drop(x + k)
        }
    }

    Nat.induction(f)

    f(Nat.0)

    forall(x: Nat) {
        if f(x) {
            forall(l: List[T], k: Nat) {
                // Induction hypothesis: l.drop(x).drop(k) = l.drop(x + k)
                l.drop(x.suc).drop(k) = l.drop(x.suc + k)
            }
        }
    }

}

attributes List[T] {
    /// Removes the last n elements from the list.
    define drop_last(self, n: Nat) -> List[T] {
        match self {
            List.nil {
                List.nil[T]
            }
            List.cons(head, tail) {
                if tail.length < n {
                    List.nil[T]
                } else {
                    List.cons(head, tail.drop_last(n))
                }
            }
        }
    }
}

theorem drop_last_zero[T](a: List[T]) {
    a.drop_last(Nat.0) = a
} by {
    define q(x: List[T]) -> Bool {
        x.drop_last(Nat.0) = x
    }
    forall(head: T, tail: List[T]) {
        if q(tail) {
            q(List.cons(head, tail))
        }
    }
}

theorem drop_last_all[T](l: List[T]) {
    l.drop_last(l.length) = List.nil[T]
} by {
    define r(x: List[T]) -> Bool {
        x.drop_last(x.length) = List.nil[T]
    }
    forall(head: T, tail: List[T]) {
        if r(tail) {
            r(List.cons(head, tail))
        }
    }
}

theorem drop_last_cancels_add[T](a: List[T], b: List[T]) {
    (a + b).drop_last(b.length) = a
} by {
    define p(x: List[T]) -> Bool {
        (x + b).drop_last(b.length) = x
    }
    drop_last_all(b)
    forall(head: T, tail: List[T]) {
        if p(tail) {
            List.cons(head, tail + b).drop_last(b.length) = List.cons(head, (tail + b).drop_last(b.length))
            p(List.cons(head, tail))
        }
    }
}

attributes Nat {
    /// Creates a list of natural numbers from self to n-1 (exclusive of n).
    define until(self, n: Nat) -> List[Nat] {
        n.range.drop(self)
    }

    /// Creates a list of natural numbers from self to n (inclusive).
    define upto(self, n: Nat) -> List[Nat] {
        self.until(n.suc)
    }
}

theorem zero_until(n: Nat) {
    Nat.0.until(n) = n.range
} by {
    drop_zero(n.range)
}

theorem until_self(n: Nat) {
    n.until(n) = List.nil[Nat]
} by {
    drop_cancels_add(n.range, List.nil[Nat])
}

theorem until_suc(n: Nat) {
    n.until(n.suc) = List.singleton(n)
} by {
    drop_cancels_add(n.range, List.singleton(n))
}

theorem zero_upto(n: Nat) {
    Nat.0.upto(n) = n.suc.range
}

theorem upto_self(n: Nat) {
    n.upto(n) = List.singleton(n)
}

theorem range_add_until(a: Nat, b: Nat) {
    a <= b implies a.range + a.until(b) = b.range
} by {
    let (k: Nat) satisfy { a + k = b }

    define f(x: Nat) -> Bool {
        a.range + a.until(a + x) = (a + x).range
    }

    // Base case: x = 0
    until_self(a)
    f(Nat.0)

    // Inductive step
    forall(x: Nat) {
        if f(x) {
            // Show a.until(a + x.suc) = a.until(a + x) + List.singleton(a + x)
            drop_cancels_add(a.range, a.until(a + x) + List.singleton(a + x))

            // Now show f(x.suc)
            add_assoc(a.range, a.until(a + x), List.singleton(a + x))
            f(x.suc)
        }
    }

    f(k)
}

// Could be generalized to arbitrary functions over a set with 0, not
// necessarily associative as in `add`. `LinearOrder` with smallest element 0
// would similarly work (or with `option`). Technically `Nat`s w/ `max` defines a
// `Monoid`, which would also work w/ definition of `add` above.
define max_list(list: List[Nat]) -> Nat {
    match list {
        List[Nat].nil {
            0
        }
        List.cons(head, tail) {
            head.max(max_list(tail))
        }
    }
}

theorem list_has_max(list: List[Nat], n: Nat) {
    max_list(list) <= n implies
    forall(m: Nat) {
        list.contains(m) implies m <= n
    }
} by {
    define f(l: List[Nat]) -> Bool {
        forall(k: Nat) {
            l.contains(k) implies k <= max_list(l)
        }
    }

    forall(head: Nat, tail: List[Nat]) {
        if f(tail) {
            let k = max_list(tail)
            let m: Nat = head.max(k)
            m >= max_list(tail)
            forall(x: Nat) {
                tail.contains(x) implies x <= m

                List.cons(head, tail).contains(x) implies x <= m
            }

            f(List.cons(head, tail))
        }
    }

    f(list)
}

theorem no_list_contains_nat(list: List[Nat]) {
    exists(n: Nat) {
        not list.contains(n)
    }
}

from option import Option

attributes List[T] {
    /// The index of the first occurrence of the item in the list.
    /// Returns the list length if the item is not found.
    define find_first_idx(self, item: T) -> Nat {
        match self {
            List.nil{
                Nat.0
            }
            List.cons(head, tail) {
                if head = item {
                    Nat.0
                } else {
                    1 + tail.find_first_idx(item)
                }
            }
        }
    }

    /// The element at index i, or none if the index is out of bounds.
    define get_idx(self, i: Nat) -> Option[T] {
        match self {
            List.nil {
                Option.none
            }
            List.cons(head, tail) {
                if i > 0 {
                    tail.get_idx(i - 1)
                } else {
                    Option.some(head)
                }
            }
        }
    }
}

theorem find_first_idx_contains[T](list: List[T], item: T) {
    list.contains(item) implies list.find_first_idx(item) < list.length
} by {
    define p(l: List[T]) -> Bool {
        l.contains(item) implies l.find_first_idx(item) < l.length
    }

    // Base case: empty list does not contain any item

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            if List.cons(head, tail).contains(item) {
                if head = item {
                    p(List.cons(head, tail))
                } else {
                    p(List.cons(head, tail))
                }
            }
        }
    }

}

theorem find_first_idx_get_idx[T](list: List[T], item: T) {
    list.contains(item) implies
    list.get_idx(list.find_first_idx(item)) = Option.some(item)
} by {
    define p(l: List[T]) -> Bool {
        l.contains(item) implies
        l.get_idx(l.find_first_idx(item)) = Option.some(item)
    }

    // Base case: empty list does not contain any item

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            if List.cons(head, tail).contains(item) {
                if head = item {
                    // If head is the item, then find_first_idx returns 0 and get_idx(0) returns head

                    p(List.cons(head, tail))
                } else {
                    // If not, then find_first_idx returns the index in tail and get_idx returns the item
                    let idx = tail.find_first_idx(item)
                    List.cons(head, tail).get_idx(1 + idx) = tail.get_idx(idx)

                    p(List.cons(head, tail))
                }
            }
        }
    }

}

theorem get_idx_succ_implies_tail[T](list: List[T], i: Nat) {
    i + 1 < list.length implies list.get_idx(i + 1) = list.tail.get_idx(i)
} by {
    define p(l: List[T]) -> Bool {
        i + 1 < l.length implies l.get_idx(i + 1) = l.tail.get_idx(i)
    }

    // Base case: empty list does not have any valid index
    p(List.nil[T])

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            if i + 1 < List.cons(head, tail).length {
                List.cons(head, tail).get_idx(i + 1) = tail.get_idx(i)

                p(List.cons(head, tail))
            }
        }
    }

}

theorem duplicate_implies_duplicate_idx[T](list: List[T], item: T) {
    list.count(item) > 1 implies
    exists(i: Nat, j: Nat) {
        i < j and j < list.length and
        list.get_idx(i) = Option.some(item) and
        list.get_idx(j) = Option.some(item)
    }
} by {
    define p(l: List[T]) -> Bool {
        l.count(item) > 1 implies
        exists(i: Nat, j: Nat) {
            i < j and j < l.length and
            l.get_idx(i) = Option.some(item) and
            l.get_idx(j) = Option.some(item)
        }
    }

    // Base case: empty list does not contain any item
    p(List.nil[T])

    // Inductive step
    forall(head: T, tail: List[T]) {
        if p(tail) {
            if List.cons(head, tail).count(item) > 1 {
                if head = item {
                    // If head is the item, then we need one more in the tail
                    tail.contains(item)
                    let idx = tail.find_first_idx(item)
                    idx + 1 < tail.length + 1
                    List.cons(head, tail).get_idx(idx + 1) = tail.get_idx(idx)

                    // Indices
                    let i = 0
                    let j = idx + 1
                    i < j
                    List.cons(head, tail).get_idx(i) = Option.some(head)

                    p(List.cons(head, tail))
                } else {
                    // If head is not the item, then we need two in the tail

                    let (i: Nat, j: Nat) satisfy {
                        i < j and j < tail.length and
                        tail.get_idx(i) = Option.some(item) and
                        tail.get_idx(j) = Option.some(item)
                    }

                    i + 1 > 0
                    List.cons(head, tail).get_idx(i + 1) = tail.get_idx(i)
                    j + 1 > 0
                    List.cons(head, tail).get_idx(j + 1) = tail.get_idx(j)

                    i + 1 < j + 1
                    p(List.cons(head, tail))
                }
            }
        }
    }

    p(list)
}

theorem index_pigeonhole[T](list: List[T]) {
    list.unique.length < list.length implies
    exists(i: Nat, j: Nat) {
        i < j and j < list.length and
        list.get_idx(i) = list.get_idx(j)
    }
}

theorem get_idx_always_some[T](list: List[T], idx: Nat) {
    idx < list.length implies exists(x: T) {
        list.get_idx(idx) = Option.some(x)
    }
} by {
    define pl(i: Nat, l: List[T]) -> Bool {
        i < l.length implies exists(x: T) {
            l.get_idx(i) = Option.some(x)
        }
    }

    define p(i: Nat) -> Bool {
        forall(l: List[T]) {
            pl(i, l)
        }
    }

    forall(l: List[T]) {
        match l {
            List.nil {
            }
            List.cons(head, tail) {
                pl(0, l)
            }
        }
    }
    p(0)

    forall(i: Nat) {
        if p(i) {
            forall(l: List[T]) {
                if i + 1 >= l.length {
                    // Trivial
                } else {
                    i + 1 < l.length
                    match l {
                        List.nil {
                        }
                        List.cons(head, tail) {
                            let x: T satisfy {
                                tail.get_idx(i) = Option.some(x)
                            }
                            pl(i+1, l)
                        }
                    }
                }
                pl(i+1, l)
            }
        }
    }

}

// This is pretty clunky unfortunately
// Might indicate that Option.some isn't great (maybe we return
// a silly object if not) or declare some monoid "lift" for
// option
/// Theorem: map(a, f).get_idx(idx) = f(a.get_idx(idx)) if idx < a.length
theorem map_under_idx[T, U](a: List[T], f: T -> U, idx: Nat) {
    idx < a.length implies exists(x: T) {
        Option.some(x) = a.get_idx(idx) and
        map(a, f).get_idx(idx) = Option.some(f(x))
    }
} by {
    define pf(i: Nat, l: List[T]) -> Bool {
        i < l.length implies exists(x: T) {
            Option.some(x) = l.get_idx(i) and
            map(l, f).get_idx(i) = Option.some(f(x))
        }
    }

    define p(i: Nat) -> Bool {
        forall(l: List[T]) {
            pf(i, l)
        }
    }

    forall(l: List[T]) {
        match l {
            List.nil {
            }
            List.cons(head, tail) {
                map(l, f).get_idx(0) = Option.some(f(head))
                pf(0, l)
            }
        }
    }
    p(0)

    forall(i: Nat) {
        if p(i) {
            forall(l: List[T]) {
                if i + 1 >= l.length {
                    // Trivial
                    pf(i+1, l)
                } else {
                    match l {
                        List.nil {
                        }
                        List.cons(head, tail) {
                            l.get_idx(i + 1) = tail.get_idx(i)
                            i < tail.length
                            let x: T satisfy {
                                tail.get_idx(i) = Option.some(x) and
                                map(tail, f).get_idx(i) = Option.some(f(x))
                            }
                            map(List.cons(head, tail), f).get_idx(i + 1) = map(tail, f).get_idx(i + 1 - 1)

                            pf(i+1, l)
                        }
                    }
                    pf(i+1, l)
                }
            }
        }
    }

    pf(idx, a)
}

theorem append_add_idx_left[T](a: List[T], b: List[T], n: Nat) {
    n < a.length implies (a + b).get_idx(n) = a.get_idx(n)
} by {
    define fp(i: Nat, l: List[T]) -> Bool {
        i < l.length implies (l + b).get_idx(i) = l.get_idx(i)
    }

    define f(i: Nat) -> Bool {
        forall(l: List[T]) {
            fp(i, l)
        }
    }

    forall(l: List[T]) {
        match l {
            List.nil {
            }
            List.cons(head, tail) {
                (l + b).get_idx(0) = Option.some(head)
                fp(0, l)
            }
        }
    }
    f(0)

    forall(i: Nat) {
        if f(i) {
            forall(l: List[T]) {
                if i+1 < l.length {
                    match l {
                        List.nil {
                        }
                        List.cons(head, tail) {
                            List.cons(head, tail).get_idx(i + 1) = (tail + b).get_idx(i)
                            i + 1 > 0
                            List.cons(head, tail + b).get_idx(i + 1) = (tail + b).get_idx(i)
                            fp(i+1, l)
                        }
                    }
                    fp(i+1, l)
                }
            }
            f(i+1)
        }
    }
}

theorem append_add_singleton_right[T](list: List[T], a: T) {
    (list + List.singleton(a)).get_idx(list.length) = Option.some(a)
} by {
    define f(l: List[T]) -> Bool {
        (l + List.singleton(a)).get_idx(l.length) = Option.some(a)
    }

    f(List.nil[T])

    forall(head: T, tail: List[T]) {
        if f(tail) {
            let l = List.cons(head, tail)
            let sa = List.singleton(a)

            (l + sa).get_idx(l.length) = (tail + sa).get_idx(l.length - 1)

            f(List.cons(head, tail))
        }
    }
}

theorem range_idx_eq_idx(n: Nat, idx: Nat) {
    idx < n implies n.range.get_idx(idx) = Option.some(idx)
} by {
    define f(m: Nat) -> Bool {
        idx < m implies m.range.get_idx(idx) = Option.some(idx)
    }

    f(0)

    forall(m: Nat) {
        if f(m) {
            if idx < m + 1 {
                if idx < m {
                    (m.range + List.singleton(m)).get_idx(idx) = m.range.get_idx(idx)
                    f(m + 1)
                } else {
                    (m.range + List.singleton(m)).get_idx(m) = Option.some(m)
                    f(m + 1)
                }
            }
        }
    }
}

theorem map_range[T](n: Nat, idx: Nat, f: Nat -> T) {
    idx < n implies map(n.range, f).get_idx(idx) = Option.some(f(idx))
} by {

    // Prover help
    map_under_idx(n.range, f, idx)

}

/// Given a function `f: Nat -> T`, if there is some `n` such that
/// `map(n.range, f).unique.length < n` (in other words, at least one element in
/// the map is repeated), then there exist indices `i < j` such that
/// `f(i) = f(j)`.
theorem range_pigeonhole[T](n: Nat, f: Nat -> T) {
    map(n.range, f).unique.length < n implies exists (i: Nat, j: Nat) {
        i < j and j < n and f(i) = f(j)
    }
} by {
    let f_out = map(n.range, f)
    f_out.length = n

    let (i: Nat, j: Nat) satisfy {
        i < j and j < n and f_out.get_idx(i) = f_out.get_idx(j)
    }

    map(n.range, f).get_idx(i) = Option.some(f(i))

    f(i) = f(j)
}

/// If an index is greater than or equal to the list length, get_idx returns none.
theorem get_idx_out_of_bounds[T](list: List[T], idx: Nat) {
    idx >= list.length implies list.get_idx(idx) = Option.none[T]
} by {
    define p(l: List[T]) -> Bool {
        forall(i: Nat) {
            i >= l.length implies l.get_idx(i) = Option.none[T]
        }
    }

    // Base case: nil

    // Inductive case
    forall(head: T, tail: List[T]) {
        if p(tail) {
            forall(i: Nat) {
                if i >= List.cons(head, tail).length {
                    // cons.length = tail.length + 1

                    if i = 0 {
                        // i = 0 but i >= tail.length.suc >= 1, contradiction
                    } else {
                        // i > 0, so cons.get_idx(i) = tail.get_idx(i-1)
                        let (i_pred: Nat) satisfy { i_pred.suc = i }
                        List.cons(head, tail).get_idx(i) = tail.get_idx(i_pred)

                        // i >= tail.length.suc means i_pred.suc >= tail.length.suc
                        // so i_pred >= tail.length

                        // By induction hypothesis
                        List.cons(head, tail).get_idx(i) = Option.none[T]
                    }
                }
            }
            p(List.cons(head, tail))
        }
    }

}

/// Helper predicate: two lists differ at some index less than n.
define differ[T](a: List[T], b: List[T], n: Nat) -> Bool {
    exists(i: Nat) {
        i < n and a.get_idx(i) != b.get_idx(i)
    }
}

/// If two lists are different and both have length at most n,
/// then there is an index i < n where they differ.
theorem lists_differ_at_index[T](a: List[T], b: List[T], n: Nat) {
    a != b and a.length <= n and b.length <= n implies differ(a, b, n)
} by {
    if a != b and a.length <= n and b.length <= n {
        define p(la: List[T]) -> Bool {
            forall(lb: List[T]) {
                la != lb and la.length <= n and lb.length <= n implies differ(la, lb, n)
            }
        }

        // Base case: a = nil
        forall(lb: List[T]) {
            if List.nil[T] != lb and List.nil[T].length <= n and lb.length <= n {
                // If nil != lb, then lb = cons(hb, tb) for some hb, tb
                let (hb: T, tb: List[T]) satisfy {
                    lb = List.cons(hb, tb)
                }

                // At index 0: nil.get_idx(0) = none, cons.get_idx(0) = some(hb)
                lb.get_idx(0) = Option.some(hb)
                List.nil[T].get_idx(0) != lb.get_idx(0)

                // lb.length >= 1, and lb.length <= n, so n >= 1, so 0 < n

                // Therefore differ holds
                differ(List.nil[T], lb, n)
            }
        }
        p(List.nil)

        // Inductive case: a = cons(ha, ta)
        forall(ha: T, ta: List[T]) {
            if p(ta) {
                forall(lb: List[T]) {
                    if List.cons(ha, ta) != lb and List.cons(ha, ta).length <= n and lb.length <= n {
                        if lb = List.nil[T] {
                            // cons != nil
                            List.cons(ha, ta).get_idx(0) = Option.some(ha)
                            List.cons(ha, ta).get_idx(0) != lb.get_idx(0)

                            // Therefore differ holds
                            differ(List.cons(ha, ta), lb, n)
                        } else {
                            // lb = cons(hb, tb) for some hb, tb
                            let (hb: T, tb: List[T]) satisfy {
                                lb = List.cons(hb, tb)
                            }

                            // Show n >= 1 since both lists are non-empty

                            List.cons(ha, ta).get_idx(0) = Option.some(ha)
                            List.cons(hb, tb).get_idx(0) = Option.some(hb)

                            if ha = hb {
                                // Heads equal, so tails must differ

                                // Apply induction
                                tb.length < n

                                // From p(ta), we get differ(ta, tb, n)
                                differ(ta, tb, n)

                                // Expand differ to get the witness
                                let (i: Nat) satisfy {
                                    i < n and ta.get_idx(i) != tb.get_idx(i)
                                }

                                // Show i.suc < n
                                if i.suc >= n {
                                    let (ip: Nat) satisfy { ip.suc = n }
                                    i = ip
                                    ta.length <= ip
                                    tb.length <= ip
                                    false
                                }

                                // Use the fact that get_idx on cons with index > 0 accesses the tail
                                // i.suc = i + 1, and i + 1 > 0

                                // By definition/theorem: cons.get_idx(i+1) = tail.get_idx(i) when i+1 > 0
                                // Or equivalently: cons.get_idx(i.suc) = tail.get_idx((i.suc) - 1) when i.suc > 0
                                // And (i.suc) - 1 = i
                                i.suc > 0
                                List.cons(ha, ta).get_idx(i.suc) = ta.get_idx(i)

                                List.cons(hb, tb).get_idx(i.suc) = tb.get_idx(i)

                                // So the cons lists differ at i.suc < n

                                // Therefore differ holds in this case
                                differ(List.cons(ha, ta), lb, n)
                            } else {
                                // Heads differ
                                0 < n

                                // Therefore differ holds in this case
                            }

                            // In both branches we've shown differ holds
                            differ(List.cons(ha, ta), lb, n)
                        }

                        // The conclusion holds for this case
                    }
                }
            }
        }

        List.induction(function (la: List[T]) {
            p(la)
        })

        p(a)
        // p(a) gives us differ(a, b, n), which expands to the existential
        differ(a, b, n)
    }
}

/// The partial sum of the zero index equals the identity element.
theorem partial_zero[A: AddCommMonoid](f: Nat -> A) {
    partial(f, Nat.0) = A.0
}


/// List extensionality: two lists with the same length that agree at all indices are equal.
theorem list_extensionality[T](a: List[T], b: List[T]) {
    a.length = b.length and (forall(i: Nat) { i < a.length implies a.get_idx(i) = b.get_idx(i) }) implies a = b
} by {
    if a.length = b.length and (forall(i: Nat) { i < a.length implies a.get_idx(i) = b.get_idx(i) }) {
        // Proof by contradiction
        if a != b {
            // Apply lists_differ_at_index with n = a.length
            lists_differ_at_index(a, b, a.length)
            differ(a, b, a.length)

            // This means there exists i < a.length where they differ

            // But we assumed they agree at all indices

            // Contradiction
        }

        // Therefore a = b
        a = b
    }
}
